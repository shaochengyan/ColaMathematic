参考
====

> - [geometric-interpretation-covariance-matrix](https://www.visiondummy.com/2014/04/geometric-interpretation-covariance-matrix/)

geometric-interpretation-covariance-matrix
==========================================

要点
----

- 掌握协方差矩阵对角线、非对角线的值的含义(大小、正负)
- 理解协方差其拉伸最大$N$个方向，分别对应于特征值从小到大排列所对应的特征向量(归一化正交的特征向量)
- 理解协方差矩阵与线性变换的关系、白数据到普通数据的变换过程、变换矩阵
- 主成分分析(PCA)

协方差矩阵
----------

variation 可以用来解释一个数据沿着某个轴的延伸程度，但是无法描述对角线的相关性，而这可以用协方差来描述，对于一个$N$维向量，将这二者总结在一个矩阵里面，即构成了协方差矩阵：
$$
\begin{equation*} \Sigma = \begin{bmatrix} \sigma(x,x) & \sigma(x,y) \\[0.3em] \sigma(y,x) & \sigma(y,y) \\[0.3em] \end{bmatrix} \end{equation*}
$$
如果$x$正相关于$y$，反之也成立，故有：$\sigma(x,y) = \sigma(y,x)$，所以协方差矩阵一般是 symmetric matrix，方差在其对角线，而协方差在非对角线。

数值大小及其意义：

- 对角线的数值越大，则代表沿着对应轴的分散程度越大
- 非对角线的值的成对大小($(x, y)$和$(y, x)$构成一对儿)反映了对应两个轴上，数据的相关性

<img src="1.协方差的几何解释.assets/covariances.png" alt="The spread of the data is defined by its covariance matrix" style="zoom:80%;" />

协方差矩阵的特征值分解
----------------------

> 明确了协方差矩阵的特征值分解中特征值、特征向量的物理意义。

如果我们想找到一个向量来表示协方差矩阵，那么我们可以先寻找一个向量，它指向数据延伸最大的方向，而其对应的的幅度则等于沿着这个方向延伸的方差。(TODO: 这很直观吗？)

假设这个向量是$\vec{v}\in \mathbb{R}^{N\times 1}$，原数据点是$D \in \mathbb{R}^{N\times K}$，则将数据点投影到该轴上后即$D' = \vec{v}^T D$(K个标量)，其方差为$\vec{v}^T \Sigma \vec{v}$，显然这样的$v$有无数个(平行)，所以我们给定$\vec v$是一个归一化的向量。由于这个方向是源数据投影过去方差最大的方向，故需要在$\vec v$为单位向量的前提下，最大化$f(\vec v) = \vec{v}^T \Sigma \vec{v}$即可。

下面寻找$\vec{v}^T \Sigma \vec{v}$的最大值，在$\vec v$ 没有任何约束的情况下，该二次型为正定二次型，故具有最小值，最大值可以无限大，但是在这里，将其限制为了$\vec v$在单位圆上，故其一定有最大值，且可以证明其最大值即最大特征值、对应的取值即对应特征向量。

总结一下：**协方差的最大特征值对应的向量，对应原数据最大方差的投影方向，这个向量的幅度，对应于其投影方差**，而第二大的则对应于第二大方差的伸展方向。

当协方差矩阵为对角阵时的例子如下，那如果不是对角阵呢？则可以旋转数据，或者说数据是被旋转过来的。

<img src="1.协方差的几何解释.assets/eigenvectors.png" style="zoom:80%;" />

协方差矩阵做线性变换
--------------------

对于原本的白数据(协方差矩阵为单位阵)，将其先做拉伸，再做旋转，即得到了右边的数据。

下面说明旋转和拉伸矩阵如何求解：对于右边的数据$D'$，我们记其协方差矩阵为$\Sigma' = Cov(D')$。首先，对$D$做$S$的拉伸，得到$D_1$，此时$Cov(D_1) = SS^T = S^2$，然后再对$D_1$做旋转得到$D' = RD_1$，此时$Cov(D') = RS(SR)^T=\Sigma'$，而$\Sigma' = P\Lambda P^T = P\sqrt{\Lambda}\sqrt{\Lambda} P^T = P\sqrt{\Lambda}(P\sqrt{\Lambda})^T $，即有$R = P$，$S = \sqrt{\Lambda}$ 

<img src="1.协方差的几何解释.assets/lineartrans.png" alt="The covariance matrix represents a linear transformation of the original data" style="zoom:80%;" />

- 即：对于给定数据$X_{n\times k}$，求得其协方差矩阵为$\Sigma = Cov(X) \in \mathbb{R}^{n\times n}$，然后将其分解得到$\Sigma= P\Lambda P^T$(其中$P$是单位正交基)。则可知$X = (P\sqrt{\Lambda})X_{white}$

协方差矩阵做PCA
---------------

设从白数据经过拉伸轴的中间数据为$X_1$，则$X_1=P^{-1}X$(旋转回去)，旋转回去后的数据$X_1$，在各个方向具有最大的方差，且方差的值等于对应的特征值，将选出最大特征值对应的特征向量进行投影，即得到了主成分。详细证明如下。

给定数据$X \in \mathbb{R}^{n\times m}$，其中$n$表示维数，$m$表述数据量，记$\Sigma = Cov(X)$，我们希望找到一个变换$T$，使得$Y = TX$后，$Y$在各轴上具有最大的方差(分散程度，即两个数据间不构成相关关关系)，即$\Sigma' = Cov(Y)= T\Sigma T^T$的非主对角线为0，主对角线上元素具有最大值。显然我们只需要找到$N$个方向，沿着这$N$个方向时数据具有最大的拉伸。这$N$个方向也就对应于$\Sigma$的特征向量，拉伸程度即对应于对应的$\sqrt{\lambda_i}$。

总结：
$$
Y = P^{-1}X
$$
